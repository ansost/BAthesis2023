{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7ebbc9",
   "metadata": {},
   "source": [
    "## Making event files from the corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf4e21a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anste145/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-11-27 22:23:35,291.291 DEBUG phonemizer:  Initializing phonemizer with model step 1120000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dp.phonemizer import Phonemizer\n",
    "phonemizer = Phonemizer.from_checkpoint('/gpfs/project/anste145/en_us_cmudict_forward.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f496ea97",
   "metadata": {
    "code_folding": [
     0,
     11,
     24,
     34
    ]
   },
   "outputs": [],
   "source": [
    "def get_context(index,word):\n",
    "    if index == 0:\n",
    "        context = 'c.' + words[index+1]\n",
    "    elif index == len(words)-1:\n",
    "        context = 'c.' + words[index-1]\n",
    "    else:\n",
    "        previous_word = 'c.' + words[index-1]\n",
    "        following_word = 'c.' + words[index+1]\n",
    "        context = previous_word + '_' + following_word \n",
    "    return context    \n",
    "\n",
    "def get_segments(word, upper = False):\n",
    "    \"\"\"Returns the segments of a word. \"\"\"\n",
    "    raw_segment_string = phonemizer(word, lang='en_us')\n",
    "    \n",
    "    if upper:\n",
    "        segments_string = re.sub(r'[\\[\\]-]',' ', raw_segment_string)\n",
    "        #segments = segments_string.split()\n",
    "        return segments_string\n",
    "    else:\n",
    "        segments_string = re.sub(r'[\\[\\]-]',' ', raw_segment_string.lower())\n",
    "        segments = segments_string.split()\n",
    "        return segments\n",
    "\n",
    "def join_segments(word):\n",
    "    \"\"\"Returns the segments of a word in a cue formatted string.\"\"\"\n",
    "    segments = get_segments(word)\n",
    "    segments_y = []\n",
    "    for segment in segments:\n",
    "        segment = 's.' + segment\n",
    "        segments_y.append(segment)\n",
    "    segments_joined = '_'.join(segments_y)\n",
    "    return segments_joined\n",
    "\n",
    "def join_syllables(syllables):\n",
    "    \"\"\"Returns the syllables of a word in a cue formatted string.\"\"\"\n",
    "    syll_list = syllables.split()\n",
    "    syllable_cuestring = []\n",
    "    for entry in syll_list:\n",
    "        syllable_cue = 'y.' + entry\n",
    "        syllable_cuestring.append(syllable_cue)\n",
    "    syllables_joined = '_'.join(syllable_cuestring)\n",
    "    return syllables_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bb0464",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s36.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:38<25:02, 38.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s24.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [01:30<29:25, 46.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s12.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [02:54<39:18, 63.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s25.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [04:04<39:33, 65.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s13.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [05:24<41:34, 71.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s01.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 9/40 [07:35<21:50, 42.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [09:28<32:03, 64.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s29.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [10:39<32:00, 66.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s30.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [11:35<29:26, 63.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s17.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [12:04<23:47, 52.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s05.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [12:37<20:14, 46.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s18.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [13:58<23:50, 57.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s06.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 16/40 [14:13<17:46, 44.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s37.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 17/40 [14:43<15:23, 40.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s38.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [15:43<16:55, 46.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s26.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 19/40 [16:06<13:42, 39.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s14.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [17:16<16:05, 48.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s02.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [18:10<15:52, 50.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s15.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 22/40 [19:19<16:43, 55.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s03.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 23/40 [19:52<13:54, 49.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s34.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [20:51<13:51, 51.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s22.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 25/40 [21:32<12:11, 48.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s35.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [22:47<13:12, 56.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s23.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [23:30<11:19, 52.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s11.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [24:34<11:10, 55.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s31.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [25:04<08:49, 48.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s32.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 30/40 [25:39<07:22, 44.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s19.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [27:35<09:53, 65.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s20.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 32/40 [27:48<06:38, 49.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s07.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 33/40 [29:20<07:17, 62.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s08.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34/40 [30:18<06:08, 61.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s39.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [31:06<04:46, 57.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s40.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 36/40 [31:56<03:40, 55.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s27.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 37/40 [32:40<02:34, 51.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s28.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 38/40 [33:31<01:43, 51.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s16.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 39/40 [35:43<01:15, 75.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're at  s04.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [36:33<00:00, 54.85s/it]\n"
     ]
    }
   ],
   "source": [
    "path = '/gpfs/project/anste145/input_files/buckeye_data/allwords_perspeaker_csv/'\n",
    "files = os.listdir(path)\n",
    "\n",
    "speakers = []\n",
    "transcriptions = {}\n",
    "\n",
    "for file in tqdm(files): \n",
    "    \n",
    "    print(\"We're at \",file)\n",
    "    \n",
    "    # List of words for the speaker\n",
    "    df = pd.read_csv(path + file)\n",
    "    words = df['token'].tolist()\n",
    "    \n",
    "    # Create new dataframe for speaker. \n",
    "    df_name = file.replace('.csv', '')\n",
    "    df = pd.DataFrame({'cues': [],'outcomes': []})\n",
    "                \n",
    "    for index, word in enumerate(words):\n",
    "        \n",
    "        # Get context.\n",
    "        context = get_context(index, word)\n",
    "        \n",
    "        # Get Segments. \n",
    "        if word not in transcriptions.keys(): \n",
    "            segments = join_segments(word)\n",
    "            raw_segments = get_segments(word, upper = True)\n",
    "            transcriptions[word] = {'cue_segments': str(segments), 'segments': str(raw_segments)} \n",
    "        else:\n",
    "            segments = transcriptions[word]['cue_segments']\n",
    "        \n",
    "        # Get syllables. \n",
    "        raw_syllables = stringify(syllabify(English, transcriptions[word]['segments']))\n",
    "        syllables = join_syllables(raw_syllables)\n",
    "\n",
    "        # Append all cue strings and clean track boundaries\n",
    "        cues = context + '_' + syllables.lower() + '_' + segments\n",
    "        if 'NA_' in cues:\n",
    "            cues = cues.replace('NA','')\n",
    "        \n",
    "        # Append all information to the dataframe as a new row. \n",
    "        df.loc[len(df)] = {'cues': str(cues),'outcomes': str(word)}\n",
    "        \n",
    "        # Save individual speaker dataframe. \n",
    "        df.to_csv('/gpfs/project/anste145/input_files/buckeye_data/event_files/' + df_name + '.tsv')  \n",
    "        speakers.append(df)\n",
    "        \n",
    "# Concat all individual speaker dataframes into one dataframe. \n",
    "buckeye_event_file = pd.concat(speakers)\n",
    "buckeye_event_file.to_csv('/gpfs/project/anste145/output/buckeye_event_file.tsv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01132adf",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# English language settings for the language parameter in the syllabifier.\n",
    "English = {\n",
    "    'consonants': ['B', 'CH', 'D', 'DH', 'F', 'G', 'HH', 'JH', 'K', 'L',\n",
    "                   'M', 'N', 'NG', 'P', 'R', 'S', 'SH', 'T', 'TH', 'V', 'W',\n",
    "                   'Y', 'Z', 'ZH'],\n",
    "    'vowels': [ 'AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', 'IH',\n",
    "               'IY', 'OW', 'OY', 'UH', 'UW'],\n",
    "    'onsets': ['P', 'T', 'K', 'B', 'D', 'G', 'F', 'V', 'TH', 'DH', 'S', 'Z',\n",
    "               'SH', 'CH', 'JH', 'M', 'N', 'R', 'L', 'HH', 'W', 'Y', 'P R',\n",
    "               'T R', 'K R', 'B R', 'D R', 'G R', 'F R', 'TH R', 'SH R',\n",
    "               'P L', 'K L', 'B L', 'G L', 'F L', 'S L', 'T W', 'K W',\n",
    "               'D W','S W', 'S P', 'S T', 'S K', 'S F', 'S M', 'S N', 'G W',\n",
    "               'SH W', 'S P R', 'S P L', 'S T R', 'S K R', 'S K W', 'S K L',\n",
    "               'TH W', 'ZH', 'P Y', 'K Y', 'B Y', 'F Y', 'HH Y', 'V Y',\n",
    "               'TH Y', 'M Y', 'S P Y', 'S K Y', 'G Y', 'HH W', '']\n",
    "    }\n",
    "     \n",
    "def syllabify(language, word):\n",
    "    '''Syllabifies the word, given a language configuration loaded with\n",
    "    loadLanguage. word is either a string of phonemes from the CMU\n",
    "    pronouncing dictionary set (with optional stress numbers after vowels),\n",
    "    or a Python list of phonemes, e.g. \"B AE1 T\" or [\"B\", \"AE1\", \"T\"]\n",
    "    '''\n",
    "\n",
    "    if type(word) == str:\n",
    "        word = word.split()\n",
    "    # This is the returned data structure.\n",
    "    syllables = []\n",
    "\n",
    "    # This maintains a list of phonemes between nuclei.\n",
    "    internuclei = []\n",
    "\n",
    "    for phoneme in word :\n",
    "\n",
    "        phoneme = phoneme.strip()\n",
    "        if phoneme == \"\" :\n",
    "            continue\n",
    "        stress = None\n",
    "        if phoneme[-1].isdigit() :\n",
    "            stress = int(phoneme[-1])\n",
    "            phoneme = phoneme[0:-1]\n",
    "\n",
    "        # Split the consonants seen since the last nucleus into coda and\n",
    "        # onset.\n",
    "        if phoneme in language[\"vowels\"] :\n",
    "\n",
    "            coda = None\n",
    "            onset = None\n",
    "\n",
    "            # If there is a period in the input, split there.\n",
    "            if \".\" in internuclei :\n",
    "                period = internuclei.index(\".\")\n",
    "                coda = internuclei[:period]\n",
    "                onset = internuclei[period+1:]\n",
    "\n",
    "            else :\n",
    "                # Make the largest onset we can. The 'split' variable marks\n",
    "                # the break point.\n",
    "                for split in range(0, len(internuclei)+1) :\n",
    "                    coda = internuclei[:split]\n",
    "                    onset = internuclei[split:]\n",
    "\n",
    "                    # If we are looking at a valid onset, or if we're at the\n",
    "                    # start of the word (in which case an invalid onset is\n",
    "                    # better than a coda that doesn't follow a nucleus), or\n",
    "                    # if we've gone through all of the onsets and we didn't\n",
    "                    # find any that are valid, then split the nonvowels\n",
    "                    # we've seen at this location.\n",
    "                    if \" \".join(onset) in language[\"onsets\"] \\\n",
    "                       or len(syllables) == 0 \\\n",
    "                       or len(onset) == 0 :\n",
    "                       break\n",
    "\n",
    "\n",
    "            # Tack the coda onto the coda of the last syllable. Can't do it\n",
    "            # if this is the first syllable.\n",
    "            if len(syllables) > 0 :\n",
    "                syllables[-1][3].extend(coda)\n",
    "\n",
    "            # Make a new syllable out of the onset and nucleus.\n",
    "            syllables.append( (stress, onset, [phoneme], []) )\n",
    "\n",
    "            # At this point we've processed the internuclei list.\n",
    "            internuclei = []\n",
    "\n",
    "        elif not phoneme in language[\"consonants\"] and phoneme != \".\" :\n",
    "            raise ValueError(\"Invalid phoneme: \" + phoneme)\n",
    "\n",
    "        else : # a consonant\n",
    "            internuclei.append(phoneme)\n",
    "\n",
    "    # Done looping through phonemes. We may have consonants left at the end.\n",
    "    # We may have even not found a nucleus.\n",
    "    if len(internuclei) > 0 :\n",
    "        if len(syllables) == 0 :\n",
    "            syllables.append( (None, internuclei, [], []) )\n",
    "        else :\n",
    "            syllables[-1][3].extend(internuclei)\n",
    "\n",
    "    return syllables\n",
    "\n",
    "def stringify(syllables) :\n",
    "    '''This function takes a syllabification returned by syllabify and\n",
    "       turns it into a string, with phonemes spearated by spaces and\n",
    "       syllables spearated by periods.'''\n",
    "    ret = []\n",
    "    for syl in syllables :\n",
    "        stress, onset, nucleus, coda = syl\n",
    "        if stress != None and len(nucleus) != 0 :\n",
    "            nucleus[0] += str(stress)\n",
    "        ret.append(\"\".join(onset + nucleus + coda))\n",
    "    return \" \".join(ret)\n",
    "\n",
    "language = English"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

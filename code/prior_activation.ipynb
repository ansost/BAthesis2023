{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from variablesOtherPrior import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the event file, weights and parts of the regression dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13809 entries, c.okay to y.jhihts\n",
      "Columns: 9558 entries, okay to looser\n",
      "dtypes: float64(9558)\n",
      "memory usage: 1007.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Event file.\n",
    "event_file = pd.read_csv('../data/final_eventfile_buckeye.gz', \n",
    "                         sep = '\\t', \n",
    "                         low_memory = True,\n",
    "                         engine = 'c')\n",
    "\n",
    "# The word column from the regression dataframe.  \n",
    "speaker_word = pd.read_csv('../data/regression_data.csv',\n",
    "                           usecols=['wordID'],\n",
    "                           dtype={\"wordID\": \"category\"},\n",
    "                           low_memory = True, \n",
    "                           engine = 'c')\n",
    "\n",
    "# Weights. \n",
    "df = xr.open_dataarray('../output/weights/weights_buckeye.nc')\n",
    "weight_matrix = df.to_pandas()\n",
    "weight_matrix = weight_matrix.transpose()\n",
    "weight_matrix.info(verbose=False, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add prior to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276845it [14:40, 314.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276845it [45:38, 101.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading df...\n",
      "Concating...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "concat() got an unexpected keyword argument 'objects'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m\n\u001b[1;32m     32\u001b[0m regression_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/regression_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     33\u001b[0m                               dtype\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeakerID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeakerAge\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeakerGender\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterviewerGender\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwordID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwordDur\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwordPOS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_segments\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_syllables\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m}, \n\u001b[1;32m     36\u001b[0m                               engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     37\u001b[0m                               low_memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcating...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mregression_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m result\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/regression_data_otherPrior.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: concat() got an unexpected keyword argument 'objects'"
     ]
    }
   ],
   "source": [
    "words = speaker_word['wordID'].tolist()\n",
    "\n",
    "prior_dict = {}\n",
    "\n",
    "# Make a prior dictionary.\n",
    "for index, word in tqdm(enumerate(words)):\n",
    "    if word not in prior_dict.keys(): \n",
    "\n",
    "        prior_all = get_prior(weight_matrix = weight_matrix, word_outcome = word, domain_specific = False)\n",
    "        priors = get_prior(weight_matrix = weight_matrix, word_outcome = word, domain_specific = True)\n",
    "        \n",
    "        prior_dict[word] = {'prior_all': prior_all, \n",
    "                            'prior_segments': priors['Segment'], \n",
    "                            'prior_syllables': priors['Syllable'], \n",
    "                            'prior_context' : priors['Context']} \n",
    "# Save to json. \n",
    "out_file = open(\"../data/otherPrior_dictionary.json\", \"w\")\n",
    "json.dump(prior_dict, out_file, indent = 6)\n",
    "out_file.close()\n",
    "    \n",
    "df = pd.DataFrame({'prior_all': [], 'prior_segments': [], 'prior_syllables' : [], 'prior_context': []})\n",
    "\n",
    "print('Filling..')\n",
    "for index, word in tqdm(enumerate(words)):\n",
    "    df.at[index, 'prior_all'] = prior_dict[word]['prior_all']\n",
    "    df.at[index, 'prior_segments'] = prior_dict[word]['prior_segments']\n",
    "    df.at[index, 'prior_syllables'] = prior_dict[word]['prior_syllables']\n",
    "    df.at[index, 'prior_context'] = prior_dict[word]['prior_context']\n",
    "\n",
    "print('Loading df...')\n",
    "# Loading whole regression dataset.\n",
    "regression_data = pd.read_csv('../data/regression_data.csv', \n",
    "                              dtype={\"speakerID\": \"category\",\"speakerAge\": \"category\", \"speakerGender\": \"category\",\n",
    "                                     \"interviewerGender\": \"category\", \"wordID\": \"category\", \"wordDur\": \"float\",\n",
    "                                     \"wordPOS\": \"category\", \"n_segments\": \"category\", \"n_syllables\": \"category\"}, \n",
    "                              engine = 'c',\n",
    "                              low_memory = True)\n",
    "print('Concating...')\n",
    "result = pd.concat(objs = [regression_data, df], axis = 1)\n",
    "result.to_csv('../data/regression_data_otherPrior.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add activation to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = speaker_word['wordID'].tolist()\n",
    "\n",
    "df = pd.DataFrame({'activation_all': [], 'activation_segments': [], 'activation_syllables' : [], \n",
    "                   'activation_context': []})\n",
    "\n",
    "for index, word in tqdm(enumerate(words)): \n",
    "    if index == 0:\n",
    "        c1 = 'c.' + words[index+1]\n",
    "        c2 = None\n",
    "    elif index == len(words)-1:\n",
    "        c1 = 'c.' + words[index-1]\n",
    "        c2 = None\n",
    "    else:\n",
    "        c1 = 'c.' + words[index-1]\n",
    "        c2 = 'c.' + words[index+1]\n",
    "    \n",
    "    act = activation(word_outcome = word, c1 = c1, c2=c2, \n",
    "           event_files = [event_file], weight_matrix = weight_matrix, \n",
    "           domain_specific = False)\n",
    "    act_domain = activation(word_outcome = word, c1 = c1, c2=c2,  \n",
    "           event_files = [event_file], weight_matrix = weight_matrix, \n",
    "           domain_specific = True)\n",
    "    \n",
    "    df.at[index, 'activation_all'] = act\n",
    "    df.at[index, 'activation_segments'] = act_domain['Segment']\n",
    "    df.at[index, 'activation_syllables'] = act_domain['Syllable']\n",
    "    df.at[index, 'activation_context'] = act_domain['Context']\n",
    "    \n",
    "print('Loading data')\n",
    "# Loading whole regression dataset.\n",
    "regression_data = pd.read_csv('../data/regression_data_prior.csv', \n",
    "                              dtype={\"speakerID\": \"category\",\"speakerAge\": \"category\", \"speakerGender\": \"category\",\n",
    "                                     \"interviewerGender\": \"category\", \"wordID\": \"category\", \"wordDur\": \"float\",\n",
    "                                     \"wordPOS\": \"category\", \"n_segments\": \"category\", \"n_syllables\": \"category\"}, \n",
    "                              engine = 'c',\n",
    "                              low_memory = True)    \n",
    "\n",
    "ende = pd.concat(obs = [regression_data, df], axis = 1)\n",
    "ende.to_csv('../data/regression_data_activation.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ende = pd.concat(objs = [regression_data, df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ende.to_csv('../data/regression_data_activation.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
